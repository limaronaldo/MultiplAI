#!/usr/bin/env bun
/**
 * Script para criar issues no GitHub para o projeto MultiplAI v2
 * Essas issues ser√£o processadas pelo pr√≥prio MultiplAI
 *
 * Uso: bun run scripts/create-github-issues.ts
 */

import { Octokit } from "octokit";

const REPO_OWNER = "limaronaldo";
const REPO_NAME = "MultiplAI";

interface IssueDefinition {
  title: string;
  body: string;
  labels: string[];
  wave: number;
}

const ISSUES: IssueDefinition[] = [
  // WAVE 1 - Hardening
  {
    title: "[Wave 1] Refatorar tipos de Task/TaskEvent e documentar state machine",
    wave: 1,
    labels: ["auto-dev", "wave-1", "complexity-S"],
    body: `## Contexto
Antes de evoluir o MultiplAI, precisamos consolidar os tipos core e garantir que a state machine esteja bem documentada e testada. Isso facilita futuras modifica√ß√µes autom√°ticas.

## Requisitos
- Consolidar todos os tipos em \`src/core/types.ts\` com coment√°rios JSDoc explicando cada campo
- Documentar \`TaskStatus\` e \`StatusTransitions\` em \`src/core/state-machine.ts\` com coment√°rios inline
- Criar arquivo \`src/core/__tests__/state-machine.test.ts\` com testes unit√°rios:
  - Testar todas as transi√ß√µes v√°lidas
  - Testar que transi√ß√µes inv√°lidas lan√ßam erro
  - Testar \`isTerminal()\` para estados finais
  - Testar \`getNextAction()\` para cada estado

## Arquivos alvo
- \`src/core/types.ts\`
- \`src/core/state-machine.ts\`
- \`src/core/__tests__/state-machine.test.ts\` (criar)

## Definition of Done
- [ ] Todos os tipos em \`types.ts\` t√™m coment√°rios JSDoc
- [ ] \`TaskStatus\` tem enum documentado com descri√ß√£o de cada estado
- [ ] \`state-machine.ts\` tem coment√°rios explicando cada transi√ß√£o
- [ ] Arquivo de testes criado com pelo menos 10 casos de teste
- [ ] Testes passam com \`bun test\`

## Complexidade: S (Small) - Refatora√ß√£o sem mudan√ßa de l√≥gica

## Linear Issue
RML-78
`,
  },
  {
    title: "[Wave 1] Melhorar estrutura de logs e tracking de eventos",
    wave: 1,
    labels: ["auto-dev", "wave-1", "complexity-S"],
    body: `## Contexto
Os logs atuais v√£o para console. Precisamos de uma estrutura mais robusta para debugging e auditoria, especialmente quando o MultiplAI processar m√∫ltiplas tasks.

## Requisitos
- Criar \`src/core/logger.ts\` com:
  - Fun√ß√£o \`createTaskLogger(taskId: string)\` que retorna logger contextualizado
  - N√≠veis: debug, info, warn, error
  - Formato estruturado: \`[TIMESTAMP] [LEVEL] [TASK_ID] [AGENT] message\`
  - Op√ß√£o de salvar em arquivo via env \`LOG_TO_FILE=true\`
- Atualizar \`Orchestrator\` para usar o novo logger em vez de \`console.log\`
- Garantir que \`logEvent\` nunca quebre o fluxo (j√° tem try/catch, melhorar mensagem)

## Arquivos alvo
- \`src/core/logger.ts\` (criar)
- \`src/core/orchestrator.ts\`

## Definition of Done
- [ ] \`logger.ts\` criado com fun√ß√µes exportadas
- [ ] Orchestrator usa \`createTaskLogger\` em todos os m√©todos
- [ ] Logs t√™m formato consistente com timestamp e task_id
- [ ] Erro em \`logEvent\` n√£o interrompe o fluxo principal
- [ ] Vari√°vel \`LOG_TO_FILE\` documentada em \`.env.example\`

## Complexidade: S (Small)

## Linear Issue
RML-79
`,
  },
  {
    title: "[Wave 1] Hardening do Orchestrator: valida√ß√µes e error handling",
    wave: 1,
    labels: ["auto-dev", "wave-1", "complexity-M"],
    body: `## Contexto
O Orchestrator precisa ser mais defensivo antes de chamar agentes, validando estados e inputs para evitar erros silenciosos.

## Requisitos
- Adicionar valida√ß√£o no in√≠cio de cada m√©todo \`run*\`:
  - Verificar se \`task.status\` √© o esperado para aquela a√ß√£o
  - Verificar se campos obrigat√≥rios existem (ex: \`branchName\` antes de \`runTests\`)
  - Lan√ßar erro claro se valida√ß√£o falhar
- Melhorar \`failTask\`:
  - Incluir stack trace quando dispon√≠vel
  - Adicionar coment√°rio na issue do GitHub com o erro (opcional, via config)
- Criar tipo \`OrchestratorError\` com campos: \`code\`, \`message\`, \`taskId\`, \`recoverable\`

## Arquivos alvo
- \`src/core/orchestrator.ts\`
- \`src/core/types.ts\`

## Definition of Done
- [ ] Cada m√©todo \`run*\` tem valida√ß√£o de estado no in√≠cio
- [ ] Erros de valida√ß√£o t√™m mensagens claras indicando o problema
- [ ] \`OrchestratorError\` type criado e usado em \`failTask\`
- [ ] Coment√°rio opcional na issue quando task falha (config: \`COMMENT_ON_FAILURE=true\`)
- [ ] Testes de valida√ß√£o n√£o quebram fluxo existente

## Complexidade: M (Medium)

## Linear Issue
RML-80

## Dependencies
- RML-78 (Refatorar tipos)
`,
  },

  // WAVE 2 - Job/Batch Layer
  {
    title: "[Wave 2] Adicionar entidade Job e endpoints /jobs para batch processing",
    wave: 2,
    labels: ["wave-2", "complexity-M"],
    body: `## Contexto
Atualmente processamos uma issue por vez. Precisamos de uma camada \`Job\` que agrupa m√∫ltiplas tasks para processamento em batch.

## Requisitos
- Criar tipo \`Job\` em \`src/core/types.ts\`:
\`\`\`typescript
interface Job {
  id: string;
  status: JobStatus; // 'pending' | 'running' | 'completed' | 'failed' | 'partial'
  taskIds: string[];
  createdAt: Date;
  updatedAt: Date;
  summary?: JobSummary;
}

interface JobSummary {
  total: number;
  completed: number;
  failed: number;
  prsCreated: string[]; // URLs dos PRs
}
\`\`\`
- Criar \`src/integrations/db-jobs.ts\` com fun√ß√µes:
  - \`createJob(job: Job): Promise<Job>\`
  - \`getJob(id: string): Promise<Job | null>\`
  - \`updateJob(id: string, updates: Partial<Job>): Promise<Job>\`
  - \`listJobs(limit?: number): Promise<Job[]>\`
- Adicionar endpoints em \`src/router.ts\`:
  - \`POST /api/jobs\` - cria job com lista de issue numbers
  - \`GET /api/jobs\` - lista jobs recentes
  - \`GET /api/jobs/:id\` - detalhes do job com status de cada task
  - \`GET /api/jobs/:id/events\` - eventos agregados de todas as tasks

## Arquivos alvo
- \`src/core/types.ts\`
- \`src/integrations/db-jobs.ts\` (criar)
- \`src/router.ts\`

## Definition of Done
- [ ] Tipo \`Job\` e \`JobStatus\` definidos em types.ts
- [ ] Fun√ß√µes de DB para jobs implementadas
- [ ] Endpoint POST /api/jobs cria job e tasks associadas
- [ ] Endpoint GET /api/jobs/:id retorna job com status de cada task
- [ ] Documentar novos endpoints no README.md

## Complexidade: M (Medium)

## Linear Issue
RML-81

## Dependencies
- Wave 1 completed (RML-78, RML-79, RML-80)
`,
  },
  {
    title: "[Wave 2] Criar JobRunner para processar batch de tasks em paralelo",
    wave: 2,
    labels: ["wave-2", "complexity-M"],
    body: `## Contexto
Com a entidade Job criada, precisamos de um runner que processe m√∫ltiplas tasks do mesmo job em paralelo.

## Requisitos
- Criar \`src/core/job-runner.ts\`:
\`\`\`typescript
class JobRunner {
  constructor(private orchestrator: Orchestrator, private config: JobRunnerConfig) {}

  async run(job: Job): Promise<Job> {
    // 1. Atualiza job para 'running'
    // 2. Para cada taskId, dispara orchestrator.process() em paralelo
    // 3. Usa Promise.allSettled para n√£o falhar se uma task falhar
    // 4. Atualiza job.summary com resultados
    // 5. Define status final: 'completed', 'failed', ou 'partial'
  }
}

interface JobRunnerConfig {
  maxParallel: number; // default: 3
  continueOnError: boolean; // default: true
}
\`\`\`
- Integrar JobRunner no endpoint \`POST /api/jobs\`:
  - Ap√≥s criar job, iniciar processamento async
  - Retornar job_id imediatamente (n√£o bloquear)
- Adicionar endpoint \`POST /api/jobs/:id/cancel\` para interromper job

## Arquivos alvo
- \`src/core/job-runner.ts\` (criar)
- \`src/router.ts\`
- \`src/core/types.ts\`

## Definition of Done
- [ ] JobRunner implementado com processamento paralelo
- [ ] Config \`maxParallel\` limita concorr√™ncia
- [ ] Job continua mesmo se uma task falhar (quando \`continueOnError: true\`)
- [ ] Endpoint cancel marca job como 'cancelled' e para novas tasks
- [ ] Summary final tem contagem correta de completed/failed

## Complexidade: M (Medium)

## Linear Issue
RML-82

## Dependencies
- RML-81 (Entidade Job)
`,
  },
  {
    title: "[Wave 2] Webhook GitHub para criar Jobs automaticamente por label/milestone",
    wave: 2,
    labels: ["wave-2", "complexity-M"],
    body: `## Contexto
Queremos que ao adicionar uma label especial (ex: \`batch-auto-dev\`) a m√∫ltiplas issues, o MultiplAI crie um Job automaticamente.

## Requisitos
- Modificar \`src/router.ts\` handler de webhook:
  - Detectar quando issue recebe label \`batch-auto-dev\`
  - Buscar todas as issues abertas do repo com essa mesma label
  - Criar Job com todas essas issues
  - Comentar na issue que disparou: "Job criado com X issues: [link]"
- Suportar tamb√©m milestone:
  - Se issue tem label \`auto-dev\` E pertence a uma milestone
  - Criar Job com todas as issues da milestone que t√™m \`auto-dev\`
- Adicionar config em \`.env\`:
  - \`BATCH_LABEL=batch-auto-dev\`
  - \`BATCH_BY_MILESTONE=true\`

## Arquivos alvo
- \`src/router.ts\`
- \`src/integrations/github.ts\` (adicionar m√©todo para listar issues por label/milestone)
- \`.env.example\`

## Definition of Done
- [ ] Label \`batch-auto-dev\` dispara cria√ß√£o de Job
- [ ] Job inclui todas as issues com a mesma label
- [ ] Milestone mode funciona quando configurado
- [ ] Coment√°rio autom√°tico na issue trigger com link do job
- [ ] Vari√°veis documentadas em \`.env.example\`

## Complexidade: M (Medium)

## Linear Issue
RML-83

## Dependencies
- RML-81, RML-82 (Job Layer)
`,
  },

  // WAVE 3 - LangGraph Backend
  {
    title: "[Wave 3] Criar boilerplate do servi√ßo LangGraph em Python",
    wave: 3,
    labels: ["wave-3", "complexity-S"],
    body: `## Contexto
Estamos criando um novo backend em Python com LangGraph para orquestra√ß√£o mais robusta. Esta issue cria a estrutura inicial.

## Requisitos
- Criar pasta \`langgraph_service/\` na raiz com:
  - \`pyproject.toml\` com depend√™ncias:
    \`\`\`toml
    [project]
    name = "multiplai-langgraph"
    version = "0.1.0"
    dependencies = [
        "langgraph>=0.2.0",
        "langchain>=0.3.0",
        "langchain-anthropic>=0.3.0",
        "fastapi>=0.115.0",
        "uvicorn>=0.32.0",
        "pydantic>=2.0",
        "httpx>=0.28.0",
        "python-dotenv>=1.0.0",
    ]
    \`\`\`
  - \`src/multiplai/__init__.py\`
  - \`src/multiplai/schemas.py\` com tipos Pydantic equivalentes aos TS:
    - \`Task\`, \`TaskStatus\`, \`Job\`, \`JobStatus\`, \`ExecutionPlan\`
  - \`src/multiplai/config.py\` com settings via env vars
  - \`README.md\` com instru√ß√µes de setup
- Criar \`Dockerfile\` para o servi√ßo Python

## Arquivos alvo
- \`langgraph_service/\` (criar toda a estrutura)

## Definition of Done
- [ ] Estrutura de pastas criada conforme especificado
- [ ] \`pyproject.toml\` tem todas as depend√™ncias
- [ ] Schemas Pydantic equivalem aos tipos TypeScript
- [ ] \`README.md\` tem instru√ß√µes de setup com uv/pip
- [ ] Dockerfile builda corretamente

## Complexidade: S (Small) - Boilerplate apenas

## Linear Issue
RML-84
`,
  },
  {
    title: "[Wave 3] Implementar grafo LangGraph b√°sico com fluxo de issue √∫nica",
    wave: 3,
    labels: ["wave-3", "complexity-M"],
    body: `## Contexto
Criar o grafo LangGraph que replica o fluxo do Orchestrator TypeScript atual.

## Requisitos
- Criar \`langgraph_service/src/multiplai/nodes/\`:
  - \`load_context.py\` - carrega issue e arquivos do repo
  - \`plan_issue.py\` - equivalente ao PlannerAgent
  - \`execute_issue.py\` - equivalente ao CoderAgent (gera diff)
  - \`create_pr.py\` - prepara dados para cria√ß√£o de PR
- Criar \`langgraph_service/src/multiplai/graph.py\`:
  - Definir \`State\` com campos: issue, plan, diff, pr_data, status, error
  - Criar \`StateGraph\` com n√≥s conectados
  - Adicionar conditional edge para retry em caso de erro
  - Compilar com \`MemorySaver\` checkpointer
- Criar teste b√°sico que roda o grafo com mock

## Arquivos alvo
- \`langgraph_service/src/multiplai/nodes/\` (criar)
- \`langgraph_service/src/multiplai/graph.py\` (criar)
- \`langgraph_service/tests/test_graph.py\` (criar)

## Definition of Done
- [ ] Todos os n√≥s implementados como fun√ß√µes async
- [ ] Grafo compila sem erros
- [ ] Fluxo happy path: load ‚Üí plan ‚Üí execute ‚Üí create_pr
- [ ] Estado √© passado corretamente entre n√≥s
- [ ] Teste b√°sico passa com dados mock

## Complexidade: M (Medium)

## Linear Issue
RML-85

## Dependencies
- RML-84 (Boilerplate)
`,
  },
  {
    title: "[Wave 3] Expor API REST no servi√ßo LangGraph e integrar com TypeScript",
    wave: 3,
    labels: ["wave-3", "complexity-L"],
    body: `## Contexto
O servi√ßo Python precisa expor endpoints para o TypeScript atual poder delegar execu√ß√£o.

## Requisitos
- Criar \`langgraph_service/src/multiplai/api.py\` com FastAPI:
  - \`POST /jobs\` - cria job e dispara grafo async
  - \`GET /jobs/{id}\` - retorna status do job/grafo
  - \`GET /jobs/{id}/events\` - retorna eventos (JSON array)
  - \`POST /jobs/{id}/cancel\` - cancela execu√ß√£o
- Criar \`src/integrations/langgraph-client.ts\` no projeto TS:
  - Classe \`LangGraphClient\` com m√©todos: \`createJob\`, \`getStatus\`, \`getEvents\`
  - Usar \`fetch\` para chamar API Python
- Modificar \`src/core/orchestrator.ts\`:
  - Adicionar config \`executor: 'local' | 'langgraph'\`
  - Se \`langgraph\`, delegar para \`LangGraphClient\` em vez de rodar agentes locais
  - Manter fallback para modo local

## Arquivos alvo
- \`langgraph_service/src/multiplai/api.py\` (criar)
- \`src/integrations/langgraph-client.ts\` (criar)
- \`src/core/orchestrator.ts\`
- \`src/core/types.ts\`

## Definition of Done
- [ ] API Python roda em porta configur√°vel (default 8001)
- [ ] LangGraphClient implementado e exportado
- [ ] Orchestrator funciona em ambos os modos
- [ ] Flag \`EXECUTOR=langgraph\` documentada em \`.env.example\`
- [ ] Teste e2e: TS cria job ‚Üí Python processa ‚Üí TS recebe resultado

## Complexidade: L (Large) - Integra√ß√£o entre dois sistemas

## Linear Issue
RML-86

## Dependencies
- RML-85 (Grafo LangGraph)
`,
  },
];

async function main() {
  console.log("üöÄ Creating GitHub Issues for MultiplAI v2\n");

  const token = process.env.GITHUB_TOKEN;
  if (!token) {
    console.error("‚ùå GITHUB_TOKEN not set");
    process.exit(1);
  }

  const octokit = new Octokit({ auth: token });

  // Check existing issues
  console.log("üìã Checking existing issues...");
  const { data: existingIssues } = await octokit.rest.issues.listForRepo({
    owner: REPO_OWNER,
    repo: REPO_NAME,
    state: "all",
    per_page: 100,
  });

  const existingTitles = new Set(existingIssues.map((i) => i.title));
  console.log(`Found ${existingIssues.length} existing issues\n`);

  // Ensure labels exist
  console.log("üè∑Ô∏è  Ensuring labels exist...");
  const labelsToCreate = [
    { name: "auto-dev", color: "0E8A16", description: "Issue to be processed by MultiplAI" },
    { name: "wave-1", color: "1D76DB", description: "Wave 1: Hardening" },
    { name: "wave-2", color: "5319E7", description: "Wave 2: Job/Batch Layer" },
    { name: "wave-3", color: "D93F0B", description: "Wave 3: LangGraph Backend" },
    { name: "complexity-S", color: "C2E0C6", description: "Small complexity" },
    { name: "complexity-M", color: "FEF2C0", description: "Medium complexity" },
    { name: "complexity-L", color: "F9D0C4", description: "Large complexity" },
  ];

  for (const label of labelsToCreate) {
    try {
      await octokit.rest.issues.createLabel({
        owner: REPO_OWNER,
        repo: REPO_NAME,
        name: label.name,
        color: label.color,
        description: label.description,
      });
      console.log(`  ‚úÖ Created label: ${label.name}`);
    } catch (error: any) {
      if (error.status === 422) {
        console.log(`  ‚è≠Ô∏è  Label exists: ${label.name}`);
      } else {
        console.log(`  ‚ùå Error creating ${label.name}: ${error.message}`);
      }
    }
  }

  // Create issues
  console.log("\nüìù Creating issues...\n");

  const createdIssues: Array<{ number: number; title: string; wave: number }> = [];
  const skippedIssues: string[] = [];

  for (const issueDef of ISSUES) {
    // Check if already exists
    if (existingTitles.has(issueDef.title)) {
      console.log(`‚è≠Ô∏è  Skipping (exists): ${issueDef.title}`);
      skippedIssues.push(issueDef.title);
      continue;
    }

    try {
      const { data: issue } = await octokit.rest.issues.create({
        owner: REPO_OWNER,
        repo: REPO_NAME,
        title: issueDef.title,
        body: issueDef.body,
        labels: issueDef.labels,
      });

      console.log(`‚úÖ [Wave ${issueDef.wave}] #${issue.number}: ${issue.title}`);
      createdIssues.push({ number: issue.number, title: issue.title, wave: issueDef.wave });
    } catch (error: any) {
      console.log(`‚ùå Failed to create: ${issueDef.title} - ${error.message}`);
    }

    // Small delay to avoid rate limiting
    await new Promise((r) => setTimeout(r, 500));
  }

  // Summary
  console.log("\n" + "=".repeat(60));
  console.log("üìä SUMMARY");
  console.log("=".repeat(60));
  console.log(`\nRepository: https://github.com/${REPO_OWNER}/${REPO_NAME}`);
  console.log(`Issues created: ${createdIssues.length}`);
  console.log(`Issues skipped: ${skippedIssues.length}`);

  if (createdIssues.length > 0) {
    console.log("\nüìã Created Issues by Wave:");
    for (const wave of [1, 2, 3]) {
      const waveIssues = createdIssues.filter((i) => i.wave === wave);
      if (waveIssues.length > 0) {
        console.log(`\n  Wave ${wave}:`);
        waveIssues.forEach((i) => {
          console.log(`    #${i.number}: ${i.title}`);
        });
      }
    }
  }

  console.log("\nüéØ Next Steps:");
  console.log("1. Wave 1 issues have 'auto-dev' label - MultiplAI will process them");
  console.log("2. Wave 2 and 3 issues don't have 'auto-dev' label yet");
  console.log("3. After Wave 1 is complete, add 'auto-dev' to Wave 2 issues");
  console.log("4. Monitor progress at: https://github.com/" + REPO_OWNER + "/" + REPO_NAME + "/issues");

  console.log("\n‚ú® Done!");
}

main().catch((error) => {
  console.error("Fatal error:", error);
  process.exit(1);
});
