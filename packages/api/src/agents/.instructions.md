# Agent Development Instructions

This directory contains LLM-powered agents that form the core of AutoDev's autonomous development pipeline.

## Base Pattern

All agents extend `BaseAgent<Input, Output>`:

```typescript
export class MyAgent extends BaseAgent<MyInput, MyOutput> {
  async run(input: MyInput): Promise<MyOutput> {
    const prompt = await this.loadPrompt("agent-name", input);
    const response = await this.llm.chat(prompt, this.getModelConfig());
    return this.parseJSON<MyOutput>(response);
  }
}
```

## Agent Types

| Agent | Input | Output | Model |
|-------|-------|--------|-------|
| PlannerAgent | Issue + repo context | DoD + plan + effort | gpt-5.1-codex-max (high) |
| CoderAgent | Plan + files | Unified diff | Effort-based |
| FixerAgent | Error logs + diff | Corrected diff | gpt-5.1-codex-max (medium) |
| ReviewerAgent | Diff + plan | Verdict + comments | gpt-5.1-codex-max (medium) |
| BreakdownAgent | Issue | XS subtasks | Default model |

## Critical Rules

1. **Always define Zod schemas** for input/output types
2. **Load prompts from `prompts/` directory** using `loadPrompt()`
3. **Use `parseJSON<T>()`** for safe JSON extraction from LLM responses
4. **Handle non-string responses** - OpenAI Responses API may return objects
5. **Never hardcode models** - use `getModelConfig()` or model-selection.ts

## Output Format

Agents generating code must output **unified diff format**:

```diff
diff --git a/src/file.ts b/src/file.ts
--- a/src/file.ts
+++ b/src/file.ts
@@ -1,3 +1,4 @@
 existing line
+new line
 another line
```

## Error Handling

Agents should throw descriptive errors that help the Fixer agent:

```typescript
throw new Error(`Failed to generate diff: ${reason}. Context: ${relevantInfo}`);
```

## Testing

Each agent should have corresponding tests in `tests/agents/`:

```typescript
import { describe, it, expect } from "bun:test";
import { MyAgent } from "../../src/agents/my-agent";

describe("MyAgent", () => {
  it("should process input correctly", async () => {
    const agent = new MyAgent(mockLLM);
    const result = await agent.run({ task: "test" });
    expect(result.confidence).toBeGreaterThan(0);
  });
});
```
